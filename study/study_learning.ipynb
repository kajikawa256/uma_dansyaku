{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットのロード\n",
    "dataset = pd.read_pickle('./data/dataset.pkl')\n",
    "#使用する列名を指定\n",
    "resultCol = [\n",
    "    '日付','raceId','枠番','馬番','horseId','性','年齢','斤量',\n",
    "    'jockeyId','単勝','人気','trainerId','拠点','馬体重','体重増減',\n",
    "    '出走間隔','ハンデ','着順','R','コース種','コース回り','距離','天気',\n",
    "    '馬場','開催場所','グレード','制限'\n",
    "]\n",
    "recordCol = [\n",
    "    'R','頭数','枠番','馬番','単勝','人気','着順','jockeyId','斤量',\n",
    "    'タイム','着差','上り','馬体重','体重増減','出走間隔','コース種',\n",
    "    'コース回り','距離','天気','馬場','開催場所','グレード','制限','ハンデ'\n",
    "]\n",
    "pedCol = ['pedId_' + str(i) for i in range(0,62)]\n",
    "#前N走分戦績の列名を生成\n",
    "recordCol9 = []\n",
    "for i in range(1, 10):\n",
    "    tmpList = list(map(lambda x: x + '_' + str(i), recordCol))\n",
    "    recordCol9 += tmpList\n",
    "#列名を合体\n",
    "COLUMNS = resultCol + recordCol9 + pedCol\n",
    "#データセット\n",
    "dataset = dataset[COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "horseId: 100%|██████████| 63/63 [00:00<00:00, 467.04it/s]\n",
      "jockeyId: 100%|██████████| 10/10 [00:00<00:00, 1249.87it/s]\n",
      "ハンデ: 100%|██████████| 10/10 [00:00<00:00, 1000.00it/s]\n",
      "コース種: 100%|██████████| 10/10 [00:00<00:00, 799.81it/s]\n",
      "コース回り: 100%|██████████| 10/10 [00:00<00:00, 521.39it/s]\n",
      "天気: 100%|██████████| 10/10 [00:00<00:00, 647.31it/s]\n",
      "馬場: 100%|██████████| 10/10 [00:00<00:00, 733.45it/s]\n",
      "開催場所: 100%|██████████| 10/10 [00:00<00:00, 1305.82it/s]\n",
      "グレード: 100%|██████████| 10/10 [00:00<00:00, 497.39it/s]\n",
      "制限: 100%|██████████| 10/10 [00:00<00:00, 822.41it/s]\n",
      "100%|██████████| 156/156 [00:00<00:00, 4674.62it/s]\n"
     ]
    }
   ],
   "source": [
    "#ラベルエンコーディング関数の定義\n",
    "def labelEncode(df, target, recflg=False):\n",
    "    #複数列のラベルエンコーディング関数の定義\n",
    "    def listEncoder(tdf, le, cols):\n",
    "        #データフレームのコピー\n",
    "        tdf_ = tdf.copy()\n",
    "        #列名から値を取り出す\n",
    "        encoList = []\n",
    "        for col in cols:\n",
    "            encoList += tdf_[col].unique().tolist()\n",
    "        #エンコーダーを生成\n",
    "        le.fit(encoList)\n",
    "        #複数列分ループ\n",
    "        for col in tqdm(cols, desc=cols[0]):\n",
    "            #欠損データ以外の列を取り出す\n",
    "            notNull = tdf_[col][tdf_[col].notnull()]\n",
    "            #エンコード実行してindexをキーにデータフレームに書き込む\n",
    "            tdf_[col] = pd.Series(le.transform(notNull), index=notNull.index)\n",
    "            #エンコードした列はcategory列に変換\n",
    "            tdf_[col] = tdf_[col].astype('category')\n",
    "        return tdf_, le\n",
    "    #データフレームのコピー\n",
    "    tdf = df.copy()\n",
    "    #ラベルエンコーダーをインスタンス\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    #戦績かどうかで分岐\n",
    "    if not recflg:\n",
    "        #リストかどうかで分岐\n",
    "        if type(target) != list:\n",
    "            #エンコーダーの生成\n",
    "            le.fit(tdf[target])\n",
    "            #欠損データ以外の列を取り出す\n",
    "            notNull = tdf[target][tdf[target].notnull()]\n",
    "            #エンコード実行してindexをキーにデータフレームに書き込む\n",
    "            tdf[target] = pd.Series(le.transform(notNull), index=notNull.index)\n",
    "            #エンコードした列はcategory列に変換\n",
    "            tdf[target] = tdf[target].astype('category')\n",
    "        else:\n",
    "            #戦績以外で複数データだったら複数列エンコードの実行\n",
    "            tdf, le = listEncoder(tdf, le, target)\n",
    "    else:\n",
    "        #戦績データは列名にサフィックスを付与したリストを生成\n",
    "        cols9 = [target] + [target + '_' + str(i) for i in range(1, 10)]\n",
    "        #複数列エンコードの実行\n",
    "        tdf, le = listEncoder(tdf, le, cols9)\n",
    "    #データフレームとエンコーダーをreeturn\n",
    "    return tdf, le\n",
    "\n",
    "#データフレームコピー\n",
    "df = dataset.copy()\n",
    "#カテゴリ変数をラベルエンコード\n",
    "horseList = ['horseId'] + ['pedId_' + str(i) for i in range(0,62)]\n",
    "df, leHorse = labelEncode(df,horseList)\n",
    "df, leGender = labelEncode(df,'性')\n",
    "df, leTrainer = labelEncode(df,'trainerId')\n",
    "df, leHomeBase = labelEncode(df,'拠点')\n",
    "df, lejockey = labelEncode(df,'jockeyId',recflg=True)\n",
    "df, leHandi = labelEncode(df,'ハンデ',recflg=True)\n",
    "df, leType = labelEncode(df,'コース種',recflg=True)\n",
    "df, leDir = labelEncode(df,'コース回り',recflg=True)\n",
    "df, leWether = labelEncode(df,'天気',recflg=True)\n",
    "df, leCondition = labelEncode(df,'馬場',recflg=True)\n",
    "df, lePlace = labelEncode(df,'開催場所',recflg=True)\n",
    "df, leGrade = labelEncode(df,'グレード', recflg=True)\n",
    "df, leRegulation = labelEncode(df,'制限',recflg=True)\n",
    "#量的変数の列名を生成\n",
    "numericCols = ['年齢']\n",
    "cols1 = ['枠番','馬番','単勝','人気','斤量','馬体重',\n",
    "         '体重増減','出走間隔','着順','R','距離']\n",
    "cols2 = ['頭数','着順','タイム','着差','上り']\n",
    "numericCols += cols1\n",
    "cols3 = cols1 + cols2\n",
    "for i in range(1,10):\n",
    "    numericCols += map(lambda x: x + '_' + str(i),cols3)\n",
    "#量的変数に対して片変数を実行\n",
    "for col in tqdm(numericCols):\n",
    "    df[col] = df[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#着順から正解列を生成\n",
    "df['Accu'] = df['着順'].map(lambda x: 1 if x <= 3 else 0)\n",
    "#日付をキーに訓練データと検証データに分割\n",
    "sepdt = '2023/01/01'\n",
    "train = df[df['日付']<sepdt]\n",
    "test = df[df['日付']>=sepdt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#それぞれ教師データと訓練データに分割\n",
    "train_x = train.drop(['日付','着順','raceId','Accu'],axis=1)\n",
    "train_y = train['Accu']\n",
    "test_x = test.drop(['日付','着順','raceId','Accu'],axis=1)\n",
    "test_y = test['Accu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input data must be 2 dimensional and non empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\2220216\\Desktop\\uma_dansyaku\\study\\study_learning.ipynb セル 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/2220216/Desktop/uma_dansyaku/study/study_learning.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#モデルをインスタンスして学習の実行\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/2220216/Desktop/uma_dansyaku/study/study_learning.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mLGBMClassifier()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/2220216/Desktop/uma_dansyaku/study/study_learning.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_x,train_y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\sklearn.py:1142\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1140\u001b[0m             valid_sets\u001b[39m.\u001b[39mappend((valid_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1142\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1143\u001b[0m     X,\n\u001b[0;32m   1144\u001b[0m     _y,\n\u001b[0;32m   1145\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1146\u001b[0m     init_score\u001b[39m=\u001b[39;49minit_score,\n\u001b[0;32m   1147\u001b[0m     eval_set\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m   1148\u001b[0m     eval_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m   1149\u001b[0m     eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m   1150\u001b[0m     eval_class_weight\u001b[39m=\u001b[39;49meval_class_weight,\n\u001b[0;32m   1151\u001b[0m     eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[0;32m   1152\u001b[0m     eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[0;32m   1153\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m   1154\u001b[0m     categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[0;32m   1155\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1156\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model\n\u001b[0;32m   1157\u001b[0m )\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\sklearn.py:842\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    839\u001b[0m evals_result: _EvalResultDict \u001b[39m=\u001b[39m {}\n\u001b[0;32m    840\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 842\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    843\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    844\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    845\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    846\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    847\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    848\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    849\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    850\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    851\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    852\u001b[0m )\n\u001b[0;32m    854\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n\u001b[0;32m    855\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mbest_iteration\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    257\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:3200\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   3194\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   3195\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   3196\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   3197\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   3198\u001b[0m     )\n\u001b[0;32m   3199\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 3200\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   3201\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   3202\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:2276\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2269\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2270\u001b[0m                 predictor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor,\n\u001b[0;32m   2271\u001b[0m                 data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[0;32m   2272\u001b[0m                 used_indices\u001b[39m=\u001b[39mused_indices\n\u001b[0;32m   2273\u001b[0m             )\n\u001b[0;32m   2274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2275\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 2276\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel, reference\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2277\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   2278\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   2279\u001b[0m                     feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature,\n\u001b[0;32m   2280\u001b[0m                     params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, position\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposition)\n\u001b[0;32m   2281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:1861\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   1859\u001b[0m     categorical_feature \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mcategorical_feature\n\u001b[0;32m   1860\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 1861\u001b[0m     data, feature_name, categorical_feature, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m _data_from_pandas(\n\u001b[0;32m   1862\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m   1863\u001b[0m         feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m   1864\u001b[0m         categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[0;32m   1865\u001b[0m         pandas_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpandas_categorical\n\u001b[0;32m   1866\u001b[0m     )\n\u001b[0;32m   1868\u001b[0m \u001b[39m# process for args\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m params \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m params\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightgbm\\basic.py:677\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_data_from_pandas\u001b[39m(\n\u001b[0;32m    671\u001b[0m     data: pd_DataFrame,\n\u001b[0;32m    672\u001b[0m     feature_name: _LGBM_FeatureNameConfiguration,\n\u001b[0;32m    673\u001b[0m     categorical_feature: _LGBM_CategoricalFeatureConfiguration,\n\u001b[0;32m    674\u001b[0m     pandas_categorical: Optional[List[List]]\n\u001b[0;32m    675\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, List[\u001b[39mstr\u001b[39m], List[\u001b[39mstr\u001b[39m], List[List]]:\n\u001b[0;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInput data must be 2 dimensional and non empty.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    679\u001b[0m     \u001b[39m# determine feature names\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mif\u001b[39;00m feature_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Input data must be 2 dimensional and non empty."
     ]
    }
   ],
   "source": [
    "#モデルをインスタンスして学習の実行\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習モデルの評価\n",
    "Accuracy score:単純正解率。\n",
    "0を0と予測したものも正解とカウントさてるから単純に全部0と予想しても7割ぐらいの正解率になるからなし\n",
    "\n",
    "Precision score:精度。1に分類したものが実際に1だった割合\n",
    "Recall score:検出率。1のものを1として分類できた割合\n",
    "F1 score:PrecisionとRecallを複合したスコア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#検証データに対して予測実行\n",
    "prad = model.predict(test_x)\n",
    "#各種評価スコアの表示\n",
    "print('Accuracy score\\t: {}'.format(accuracy_score(prad,test_y)))\n",
    "print('Precision score\\t: {}'.format(precision_score(prad,test_y)))\n",
    "print('Recall score\\t: {}'.format(recall_score(prad,test_y)))\n",
    "print('F1 score\\t: {}'.format(f1_score(prad,test_y)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
