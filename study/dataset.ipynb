{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickleファイルからロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickleデータロード\n",
    "dfRaceResult = pd.read_pickle('./data/race_result.pkl')\n",
    "dfRaceInfo = pd.read_pickle('./data/race_Info.pkl')\n",
    "dfHorseResult = pd.read_pickle('./data/horse_result.pkl')\n",
    "dfHorsePed = pd.read_pickle('./data/horse_ped.pkl')\n",
    "#レース結果と競馬戦績にレース情報を結合\n",
    "dfRaceResulti = pd.merge(left=dfRaceResult,right=dfRaceInfo,\n",
    "                        how='left', on='raceId',suffixes=['','_i'])\n",
    "dfHorseResulti = pd.merge(left=dfHorseResult,right=dfRaceInfo,\n",
    "                        how='left', on='raceId',suffixes=['','_i'])\n",
    "#戦績テーブルからゴミを除外\n",
    "df = dfHorseResulti.copy()\n",
    "columns = []\n",
    "for cn in df.columns:\n",
    "    if '_i' not in cn:\n",
    "        columns.append(cn)\n",
    "dfHorseResulti = df[columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レース結果テーブルに成績を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 38.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#空のデータフレームを生成\n",
    "dfRaceResultH = pd.DataFrame(columns=['horseId','日付'])\n",
    "#pickleファイルの存在チェック\n",
    "if(os.path.isfile('./data/race_result_add_record.pkl')):\n",
    "    #読み込む\n",
    "    dfRaceResultH = pd.read_pickle('./data/race_result_add_record.pkl')\n",
    "\n",
    "# #レースを日付降順にソートする\n",
    "dfHorseResulti = dfHorseResulti.sort_values(('日付'),ascending=False)\n",
    "\n",
    "indexList = dfRaceResulti.index\n",
    "escapeList = dfRaceResultH.index\n",
    "\n",
    "#一時撤退用データフレームを初期化\n",
    "# saveDf = pd.DataFrame(columns=dfRaceResultH.columns)\n",
    "\n",
    "#レース結果のテーブルを1行ずつ取り出す\n",
    "for cnt, rowIndex in tqdm(enumerate(indexList), total = len(indexList)):\n",
    "    #既に処理済みのレコードだったらスキップ\n",
    "    # if rowIndex in escapeList:\n",
    "    #     continue\n",
    "    try:\n",
    "        #レース結果から1行分のデータを取り出す\n",
    "        rowDf = dfRaceResulti.loc[dfRaceResulti.index==rowIndex]\n",
    "        #horseIdと日付を取り出す\n",
    "        horseId = rowDf['horseId'].iloc[0]\n",
    "        dt = rowDf['日付'].iloc[0]\n",
    "\n",
    "        #horseIdで絞込レース結果の日付以来の直近9レース分をループ処理実行\n",
    "        #   やっていること わかりやすくしたやつ\n",
    "        # df1 = dfHorseResulti.copy()\n",
    "        # df2 = df1[df1['horseId']==horseId]\n",
    "        # df3 = df2[df2['日付']==dt]\n",
    "        # df4 = df3.head(9)\n",
    "        # for idx, tmpDf in enumerate(df4.iterrows()):\n",
    "        \n",
    "        for idx,tmpDf in \\\n",
    "            enumerate(dfHorseResulti[(dfHorseResulti['horseId']==horseId)&\\\n",
    "                                     (dfHorseResulti['日付']<dt)].head(9).iterrows()):\n",
    "            idxx = idx+1\n",
    "            tmpDfx = pd.DataFrame(tmpDf[1]).T\n",
    "            #列名にループ回数でサフィックスを付加\n",
    "            tmpDfx.columns = tmpDfx.columns + '_' + str(idxx)\n",
    "            #結合の為にidexを合わせる\n",
    "            tmpDfx.index = rowDf.index\n",
    "            #結合の実行\n",
    "            rowDf = pd.concat([rowDf, tmpDfx], axis=1)\n",
    "        #1行分のレコードを一時テーブルに結合\n",
    "        saveDf = pd.concat([saveDf, rowDf], axis=0)\n",
    "        #2000回に一度本体のテーブルに結合して一時テーブルを空にする\n",
    "        # if cnt % 2000 == 0:\n",
    "        #     dfRaceResultH = pd.concat([dfRaceResultH, saveDf], axis=0)\n",
    "        #     saveDf = pd.DataFrame(columns=dfRaceResultH.columns)\n",
    "    except:\n",
    "        print('exception catch')\n",
    "        break\n",
    "dfRaceResultH = pd.concat([dfRaceResultH, saveDf], axis=0)\n",
    "dfRaceResultH.to_pickle('./data/race_result_add_record.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for cnt, rowIndex in tqdm(enumerate(indexList), total = len(indexList)):\n",
    "#     #既に処理済みのレコードだったらスキップ\n",
    "#     if rowIndex in escapeList:\n",
    "#         continue\n",
    "#     try:\n",
    "#         #レース結果から1行分のデータを取り出す\n",
    "#         rowDf = dfRaceResulti.loc[dfRaceResulti.index==rowIndex]\n",
    "#         #horseIdと日付を取り出す\n",
    "#         horseId = rowDf['horseId'].iloc[0]\n",
    "#         dt = rowDf['日付'].iloc[0]\n",
    "\n",
    "#         #horseIdで絞込レース結果の日付以来の直近9レース分をループ処理実行\n",
    "#         for idx,tmpDf in \\\n",
    "#             enumerate(dfHorseResulti[(dfHorseResulti['horseId']==horseId)&\\\n",
    "#                                      (dfHorseResulti['日付']<dt)].head(9).iterrows()):\n",
    "#             idxx = idx+1\n",
    "#             tmpDfx = pd.DataFrame(tmpDf[1]).T\n",
    "#             #列名にループ回数でサフィックスを付加\n",
    "#             tmpDfx.columns = tmpDfx.columns + '_' + str(idxx)\n",
    "#             #結合の為にidexを合わせる\n",
    "#             tmpDfx.index = rowDf.index\n",
    "#             #結合の実行\n",
    "#             rowDf = pd.concat([rowDf, tmpDfx], axis=1)\n",
    "#         #1行分のレコードを一時テーブルに結合\n",
    "#         saveDf = pd.concat([saveDf, rowDf], axis=0)\n",
    "#         #2000回に一度本体のテーブルに結合して一時テーブルを空にする\n",
    "#         # if cnt % 2000 == 0:\n",
    "#         #     dfRaceResultH = pd.concat([dfRaceResultH, saveDf], axis=0)\n",
    "#         #     saveDf = pd.DataFrame(columns=dfRaceResultH.columns)\n",
    "#     except:\n",
    "#         print('exception catch')\n",
    "#         break\n",
    "# #dfRaceResultH\n",
    "# saveDf\n",
    "# rowDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出走間隔を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_4732\\4037590459.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['出走間隔'] = df.apply(CalcInterval, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/race_result_add_record.pkl')\n",
    "#スカラー関数の定義\n",
    "def CalcInterval(x):\n",
    "    try:\n",
    "        interval = datetime.datetime.strptime(x['日付'], '%Y/%m/%d')-\\\n",
    "                    datetime.datetime.strptime(x['日付_1'], '%Y/%m/%d')\n",
    "        return interval.days\n",
    "    except:\n",
    "        return 0\n",
    "#apply関数で一括処理\n",
    "df['出走間隔'] = df.apply(CalcInterval, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レース結果に血統データを結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaceResultP = pd.merge(left=df, right=dfHorsePed, how='left', on='horseId')\n",
    "dfRaceResultP.to_pickle('./data/dataset.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
