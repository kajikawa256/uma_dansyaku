{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レース結果のスクレイピング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レース結果をスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15360/15360 [02:59<00:00, 85.52it/s] \n"
     ]
    }
   ],
   "source": [
    "#レースIDリスト生成\n",
    "#開催年(2022と2023)\n",
    "years  = [str(i).zfill(4) for i in range(2022, 2024)]\n",
    "#開催場所(MAX10) 01札幌、02函館、03福島、04新潟、05東京、\n",
    "#                06中山、07中京、08京都、09阪神、10小倉\n",
    "place = [str(i).zfill(2) for i in range(1, 11)]\n",
    "#開催回(MAX8)\n",
    "times = [str(i).zfill(2) for i in range(1, 9)]\n",
    "#開催日(MAX8)\n",
    "days  = [str(i).zfill(2) for i in range(1, 9)]\n",
    "#レース12(MAX12)\n",
    "races = [str(i).zfill(2) for i in range(1, 13)]\n",
    "\n",
    "raceIdList = []\n",
    "for y in years:\n",
    "    for p in place:\n",
    "        for t in times:\n",
    "            for d in days:\n",
    "                for r in races:\n",
    "                    raceIdList.append(y + p + t + d + r)\n",
    "\n",
    "#URL\n",
    "pfx = 'https://db.netkeiba.com/race/'\n",
    "#readIdのリスト作成\n",
    "\n",
    "colName = ['raceId','htmlBytes']    #列名をリストで生成\n",
    "df = pd.DataFrame(columns=colName)  #データフレームの作成\n",
    "escapeList = []\n",
    "#pickleファイルの存在チェック\n",
    "if(os.path.isfile('./data/race_html.pkl')):\n",
    "    #pickleファイルを読み込む\n",
    "    df = pd.read_pickle('./data/race_html.pkl')\n",
    "    #読み込んだデータフレームから除外Idリストを作成\n",
    "    escapeList = df['raceId'].to_list()\n",
    "\n",
    "#除外リスト生成関数\n",
    "def addEscapeList(id :str, ll :list):\n",
    "    #raceIdを分解してlist化\n",
    "    idAry = [id[0:4], id[4:6], id[6:8], id[8:10],id[10:12]]\n",
    "    for r in range(1, 13):\n",
    "        idAry[4] = str(r).zfill(2)\n",
    "        ll.append(''.join(idAry))\n",
    "    if idAry[3] == '01':\n",
    "        for d in range(2,9):\n",
    "            idAry[3] = str(d).zfill(2)\n",
    "            #ll = addEscapeList(''.join(idAry), ll)\n",
    "            ll.extend(addEscapeList(''.join(idAry), []))\n",
    "    if idAry[2] == '01':\n",
    "        for t in range(2,9):\n",
    "            idAry[2] = str(t).zfill(2)\n",
    "            #ll = addEscapeList(''.join(idAry), ll)\n",
    "            ll.extend(addEscapeList(''.join(idAry), []))\n",
    "    return ll\n",
    "\n",
    "#raceIdリスト分ループ\n",
    "for raceId in tqdm(raceIdList):\n",
    "    try:\n",
    "        if raceId in escapeList:\n",
    "            continue\n",
    "        url = pfx + raceId\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        # 結果が存在しているページかチェック\n",
    "        if 'レース結果' in soup.text:\n",
    "            #データフレームを生成して一時変数に保存\n",
    "            tmpDf = pd.DataFrame([[raceId, html.content]],columns=colName)\n",
    "            #データフレームを結合\n",
    "            df = pd.concat([df, tmpDf],axis=0,ignore_index=True)\n",
    "        else:\n",
    "            #不要なページだったら除外リストを更新\n",
    "            escapeList = addEscapeList(raceId, escapeList)\n",
    "\n",
    "        time.sleep(1) #マナー間隔をあける\n",
    "    except:\n",
    "        print('exception catch')\n",
    "        break\n",
    "df.to_pickle('./data/race_html.pkl') #データフレームの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTMLからデータを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5575/5575 [04:29<00:00, 20.66it/s]\n"
     ]
    }
   ],
   "source": [
    "#保存したhtmlデータを読込\n",
    "htmlDf = pd.read_pickle('./data/race_html.pkl')\n",
    "#空のデータフレームを生成\n",
    "raceResultDf = pd.DataFrame()\n",
    "\n",
    "#保存したhtmlを1つずつ処理\n",
    "for idx, dat in tqdm(htmlDf.iterrows(), total = len(htmlDf)):\n",
    "    #idとバイナリーデータを取り出す\n",
    "    raceId = dat['raceId']\n",
    "    htmlBytes = dat['htmlBytes']\n",
    "\n",
    "    soup = BeautifulSoup(htmlBytes, 'html.parser')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    #ヘッダー用のList生成してデータフレームを生成\n",
    "    columns = []\n",
    "    #thタグをひとつずつ取り出してListに追加\n",
    "    for head in table.find_all('th'):\n",
    "        columns.append(head.text)\n",
    "    #作ったヘッダーListにraceId,horseId,jockeyId,trainerId列を追加\n",
    "    columns = ['raceId'] + columns + ['horseId', 'jockeyId', 'trainerId']\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    #テーブルを1行毎に処理\n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        #最初の行はヘッダー列なので処理をスキップ\n",
    "        if i == 0:\n",
    "            continue\n",
    "        items = [raceId]    #最初のデータにraceId\n",
    "        #1行内のtdをすべて取り出す\n",
    "        cells = row.find_all('td')\n",
    "        #1データずつ改行コードを削除素ながらデータに追加\n",
    "        for cell in cells:\n",
    "            items.append(cell.text.replace('\\n', ''))\n",
    "        #リンク先を解析しながらhorseId,jockeyId,trainerIdを切り取ってデータに追加\n",
    "        items.append(str(cells[3]).split('/horse/')[1].split('/')[0])\n",
    "        items.append(str(cells[6]).split('/recent/')[1].split('/')[0])\n",
    "        items.append(str(cells[18]).split('/recent/')[1].split('/')[0])\n",
    "        #1個分のデータを追加\n",
    "        df.loc[i] = items\n",
    "#最後に1レース分のデータフレームを追加\n",
    "raceResultDf = pd.concat([raceResultDf, df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['202308020512',\n",
       " '14',\n",
       " '8',\n",
       " '14',\n",
       " 'クリノホノオ',\n",
       " '牡6',\n",
       " '53',\n",
       " '田口貫太',\n",
       " '1:55.0',\n",
       " 'ハナ',\n",
       " '',\n",
       " '7-8-12-13',\n",
       " '40.1',\n",
       " '101.4',\n",
       " '12',\n",
       " '486(0)',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[西]谷潔',\n",
       " '栗本博晴',\n",
       " '',\n",
       " '2017101036',\n",
       " '01208',\n",
       " '00431']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceResultDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raceResultDf.copy()    #加工用にコピー\n",
    "#着外や除外などのデータを欠損データに変換\n",
    "df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "df.dropna(subset=['着順'], inplace=True)\n",
    "#性齢を性と年齢に分別\n",
    "df['性'] = df['性齢'].map(lambda x: str(x)[0])\n",
    "df['年齢'] = df['性齢'].map(lambda x: str(x)[1:])\n",
    "#馬体重と体重増減を分割して計測不のデータは欠損データに変換\n",
    "df['馬体重'] = df['馬体重'].map(lambda x: '---(-)' if '不' in x else x)\n",
    "df['体重増減'] = df['馬体重'].str.split('(', expand=True)[1].str[:-1]\n",
    "df['馬体重'] = df['馬体重'].str.split('(', expand=True)[0]\n",
    "df['馬体重'] = pd.to_numeric(df['馬体重'], errors='coerce')\n",
    "df.dropna(subset = ['馬体重'], inplace=True)\n",
    "df['体重増減'] = pd.to_numeric(df['体重増減'], errors='coerce')\n",
    "df.dropna(subset = ['体重増減'], inplace=True)\n",
    "#調教師から拠点列を取り出す\n",
    "df['拠点'] = df['調教師'].map(lambda x:\\\n",
    "    '東' if '[東]' in x else \\\n",
    "        '西' if '[西]' in x else \\\n",
    "            '地' if '[地]' in x else '外')\n",
    "# ,を除去後、空の行は0で埋める\n",
    "df['賞金'] = df['賞金(万円)'].str.replace(',','')\n",
    "df['賞金'] = pd.to_numeric(df['賞金'], errors='coerce')\n",
    "df['賞金'] = df['賞金'].fillna(0)\n",
    "\n",
    "#文字列から数値に変換\n",
    "for clna in ['着順','年齢','馬体重','体重増減','枠番','馬番']:\n",
    "    df[clna] = df[clna].astype(int)\n",
    "for clna in ['単勝','人気','賞金','斤量']:\n",
    "    df[clna] = df[clna].astype(float)\n",
    "\n",
    "#タイムを秒に変換\n",
    "df['タイム'] = df['タイム'].map(lambda x: '10:0' if x == '' else x)\n",
    "df['タイム'] = df['タイム'].map(lambda \\\n",
    "    x: float(x.split(':')[0]) * 60 + float(x.split(':')[1]))\n",
    "df['タイム'] = df['タイム'].map(lambda x: np.nan if x > 550 else x)\n",
    "#着差は1着タイムからの差分を計算して埋める\n",
    "df['着差'] = df.groupby('raceId')['タイム'].transform(lambda x: x - x.min())\n",
    "\n",
    "#一応出馬表と同じように馬番で行をソート\n",
    "df = df.sort_values(['raceId','馬番']).reset_index(drop=True)\n",
    "\n",
    "#必要な列だけ拾って列を並び替え\n",
    "columns = ['raceId','枠番','馬番','horseId','馬名','性','年齢',\n",
    "           '斤量','騎手','jockeyId','単勝','人気','調教師',\n",
    "           'trainerId','拠点','馬体重','体重増減','着順',\n",
    "           'タイム','着差','通過','上り','賞金']\n",
    "df = df[columns].copy()\n",
    "\n",
    "df.to_pickle('./data/race_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レース情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5575/5575 [07:04<00:00, 13.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#保存したhtmlデータを読み込む\n",
    "htmlDf = pd.read_pickle('./data/race_html.pkl')\n",
    "\n",
    "#空のリストの生成\n",
    "raceInfoList = []\n",
    "\n",
    "# 保存したhtmlを1つずつ処理\n",
    "for idx, dat in tqdm(htmlDf.iterrows(), total = len(htmlDf)):\n",
    "    #idとバイナリーデータを取り出す\n",
    "    raceId = dat['raceId']\n",
    "    htmlBytes = dat['htmlBytes']\n",
    "\n",
    "    #BeautifulSoupでバイナリーデータを解析\n",
    "    soup = BeautifulSoup(htmlBytes.decode('euc-jp', 'ignore'), 'html.parser')\n",
    "    \n",
    "    #情報部分を指定して取り出す\n",
    "    mainrace_data = soup.find('div', class_='mainrace_data')\n",
    "\n",
    "    #1レース分のデータを辞書型で宣言\n",
    "    rowdata = {}\n",
    "    #raceId\n",
    "    rowdata['raceId'] = raceId\n",
    "    #レース名を抽出\n",
    "    rowdata['レース名'] = mainrace_data.find('h1').text\n",
    "    #レースNoを抽出\n",
    "    rowdata['R'] = mainrace_data.find('dt').text\\\n",
    "        .replace('\\n', '').replace(' ', '').replace('R', '')\n",
    "    \n",
    "    #レース情報部のテキストを取得して'/'で分割\n",
    "    spantexts = mainrace_data.find('span').text\\\n",
    "        .replace('\\xa0', '').replace(' ', '').split('/')\n",
    "    #特定の文字列があるかどうかコース種を抽出\n",
    "    rowdata['コース種'] = '障害' if '障' in spantexts[0] else \\\n",
    "                        'ダート' if 'ダ' in spantexts[0] else '芝'\n",
    "    #レースの回りを抽出 ※開催場所で固定\n",
    "    rowdata['コース回り'] = '右' if '右' in spantexts[0] else \\\n",
    "                            '左' if '左' in spantexts[0] else '障害'\n",
    "    #距離を抽出\n",
    "    rowdata['距離'] = int(re.findall('\\d+', spantexts[0])[0])\n",
    "    #天気、馬場状態を抽出\n",
    "    rowdata['天気'] = spantexts[1][3:]\n",
    "    rowdata['馬場'] = spantexts[2].split(':')[1]\n",
    "    #発送時間を抽出 ※必要かは不明\n",
    "    rowdata['発送'] = spantexts[3][3:]\n",
    "\n",
    "    #次のレース情報部を取得していらない部分を削除して' 'で分割\n",
    "    smalltxt = mainrace_data.find('p',class_='smalltxt').text\\\n",
    "        .replace('\\xa0', ' ').replace('  ', ' ').split(' ')\n",
    "    #開催日をタイムスタンプに変換し、フォーマットを指定して保存\n",
    "    dt = datetime.datetime.strptime(smalltxt[0], '%Y年%m月%d日')\n",
    "    rowdata['日付'] = dt.strftime('%Y/%m/%d')\n",
    "    #開催場所\n",
    "    placeDict = {'01':'札幌', '02':'函館', '03':'福島', '04':'新潟', '05':'東京',\n",
    "                 '06':'中山', '07':'中京', '08':'京都', '09':'阪神', '10':'小倉'}\n",
    "    rowdata['開催場所'] = placeDict[raceId[4:6]]\n",
    "    #レースのグレードを判別\n",
    "    if 'G1' in rowdata['レース名']:\n",
    "        raceGrade = 'G1'\n",
    "    elif 'G2' in rowdata['レース名']:\n",
    "        raceGrade = 'G2'\n",
    "    elif 'G3' in rowdata['レース名']:\n",
    "        raceGrade = 'G3'\n",
    "    elif '未勝利' in smalltxt[2]:\n",
    "        raceGrade = '未勝利'\n",
    "    elif '新馬' in smalltxt[2]:\n",
    "        raceGrade = '新馬'\n",
    "    elif '1勝' in smalltxt[2] or '500万' in smalltxt[2]:\n",
    "        raceGrade = '1勝クラス'\n",
    "    elif '2勝' in smalltxt[2] or '1000万' in smalltxt[2]:\n",
    "        raceGrade = '2勝クラス'\n",
    "    elif '3勝' in smalltxt[2] or '1600万' in smalltxt[2]:\n",
    "        raceGrade = '3勝クラス'\n",
    "    else:\n",
    "        raceGrade = 'オープン'\n",
    "    rowdata['グレード'] = raceGrade\n",
    "    #出走制限を特定の文字列で判定\n",
    "    if '牡・牝' in smalltxt[3]:\n",
    "        restriction = '牡・牝'\n",
    "    elif '牝' in smalltxt[3]:\n",
    "        restriction = '牝'\n",
    "    else:\n",
    "        restriction = '無'\n",
    "    rowdata['制限'] = restriction\n",
    "    #重量制限を特定の文字列で判定\n",
    "    if 'ハンデ' in smalltxt[3]:\n",
    "        handicap = 'ハンデ'\n",
    "    elif '別定' in smalltxt[3]:\n",
    "        handicap = '別定'\n",
    "    else:\n",
    "        handicap = '定量'\n",
    "    rowdata['ハンデ'] = handicap\n",
    "    #1レース分のデータをリストに追加\n",
    "    raceInfoList.append(rowdata)\n",
    "#辞書型をデータフレームに変換\n",
    "raceInfoDf = pd.DataFrame(raceInfoList)\n",
    "#データフレームをpickleデータに保存\n",
    "raceInfoDf.to_pickle('./data/race_info.pkl')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceInfoDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "血統データをスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#レース結果読み込み\n",
    "raceResultDf = pd.read_pickle('./data/race_result.pkl')\n",
    "#URL\n",
    "pfx = 'https://db.netkeiba.com/horse/ped/'\n",
    "\n",
    "colName = ['horseId','htmlBytes']    #列名をリストで生成\n",
    "df = pd.DataFrame(columns=colName)  #データフレームの作成\n",
    "escapeList = []\n",
    "#pickleファイルの存在チェック\n",
    "if(os.path.isfile('./data/ped_html.pkl')):\n",
    "    #pickleファイルを読み込む\n",
    "    df = pd.read_pickle('./data/ped_html.pkl')\n",
    "    #読み込んだデータフレームから除外Idリストを作成\n",
    "    escapeList = df['horseId'].to_list()\n",
    "\n",
    "#raceIdリスト分ループ\n",
    "for horseId in tqdm(raceResultDf['horseId'].unique()):\n",
    "    try:\n",
    "        if horseId in escapeList:\n",
    "            continue\n",
    "        url = pfx + horseId\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        table = soup.find_all('table')[0]\n",
    "        # 結果が存在しているページかチェック\n",
    "        if len(table.find_all('a')) != 0:\n",
    "            #データフレームを生成して一時変数に保存\n",
    "            tmpDf = pd.DataFrame([[horseId, html.content]],columns=colName)\n",
    "            #データフレームを結合\n",
    "            df = pd.concat([df, tmpDf], axis=0, ignore_index=True)\n",
    "        \n",
    "        time.sleep(1) #マナー間隔をあける\n",
    "    except:\n",
    "        print('exception catch')\n",
    "        break\n",
    "    \n",
    "df.to_pickle('./data/ped_html.pkl') #データフレームの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "血統データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 15.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#保存したhtmlデータを読み込む\n",
    "htmlDf = pd.read_pickle('./data/ped_html.pkl')\n",
    "#念のためにインディックスを振り直しておく\n",
    "htmlDf = htmlDf.reset_index(drop=True)\n",
    "\n",
    "#血統を取り出す\n",
    "tergetList = [i for i in range(62)]\n",
    "\n",
    "#列名を生成\n",
    "columns = ['horseId']\n",
    "for i in range(62):\n",
    "    columns.append('pedName_' + str(i))\n",
    "    columns.append('pedId_' + str(i))\n",
    "#空のデータフレームを生成\n",
    "horsePedDf = pd.DataFrame(columns=columns)\n",
    "\n",
    "for idx, dat in tqdm(htmlDf.iterrows(), total = len(htmlDf)):\n",
    "    #horseidとhtmlBytesを取り出す\n",
    "    horseId = dat['horseId']\n",
    "    htmlBytes = dat['htmlBytes']\n",
    "\n",
    "    #BeautifulSoupでHTMLを解析\n",
    "    soup = BeautifulSoup(htmlBytes.decode('euc-jp','ignore'), 'html.parser')\n",
    "    tds = soup.find_all('table')[0].find_all('td')\n",
    "\n",
    "    #最初はhorseId\n",
    "    rowdata = [horseId]\n",
    "    for lno in tergetList:\n",
    "        #名前部分の抽出\n",
    "        rowdata.append(tds[lno].text.split('\\n')[1])\n",
    "        #IDの抽出\n",
    "        rowdata.append(str(tds[lno]).split('/horse/')[1].split('/')[0])\n",
    "    #rowdataをデータフレームに追加\n",
    "    horsePedDf.loc[idx] = rowdata\n",
    "\n",
    "#データフレーム保存\n",
    "horsePedDf.to_pickle('./data/horse_ped.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "競走馬毎レースのスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "raceResultDf = pd.read_pickle('./data/race_result.pkl')\n",
    "#競走馬IDリストの生成\n",
    "horseIdList = raceResultDf['horseId'].unique().tolist()\n",
    "\n",
    "#スクレイピング対象か買うににレース情報を読み込む\n",
    "raceInfoDf = pd.read_pickle('./data/race_info.pkl')\n",
    "#日付を確認したいからテーブル結合\n",
    "raceResultDfM = pd.merge(raceResultDf, raceInfoDf,\n",
    "                        on='raceId', how='left', suffixes=['', '_right'])\n",
    "\n",
    "#url\n",
    "pfx = 'https://db.netkeiba.com/horse/result/'\n",
    "\n",
    "colName = ['horseId', 'htmlBytes']\n",
    "df = pd.DataFrame(columns=colName)\n",
    "#pickleファイルチェック\n",
    "if (os.path.isfile('./data/horse_html.pkl')):\n",
    "    df = pd.read_pickle('./data/horse_html.pkl')\n",
    "#エラー対策をしながら空のデータフレームを生成\n",
    "horseResultDf = pd.DataFrame(columns=['horseId','raceId','日付'])\n",
    "if(os.path.isfile('./data/horse_result_pkl')):\n",
    "   horseResultDf = pd.read_pickle('./data/horse_result.pkl')\n",
    "\n",
    "for horseId in tqdm(horseIdList):\n",
    "    if horseId in horseResultDf['horseId'].unique().tolist():\n",
    "        chkR = raceResultDfM[raceResultDfM['horseId']==horseId].\\\n",
    "                    sort_values('日付').tail(1)['日付'].iloc[0]\n",
    "        chkH = horseResultDf[horseResultDf['horseId']==horseId].\\\n",
    "                    sort_values('日付').tail(1)['日付'].iloc[0]\n",
    "        if chkR != chkH:\n",
    "            #直近のレースの日付が一致しなかったらデータを消して再度スクレイピング\n",
    "            df = df[df['horseId'] != horseId]\n",
    "        else:\n",
    "            #一致したらスキップ\n",
    "            continue\n",
    "    try:\n",
    "        url = pfx + horseId\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        #結果が存在しているページかチェック\n",
    "        if len(soup.find_all('table')) != 0:\n",
    "            tmpDf = pd.DataFrame([[horseId,html.content]], columns=colName)\n",
    "            #結合\n",
    "            df = pd.concat([df, tmpDf], axis=0, ignore_index=True)\n",
    "        \n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        print('exception catch')\n",
    "        break\n",
    "df.to_pickle('./data/horse_html.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horseIdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "htmlからデータを抽出(戦績データ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:09<00:00, 14.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#保存したhtmlデータを読み込む\n",
    "htmlDf = pd.read_pickle('./data/horse_html.pkl')\n",
    "#空のデータフレームを生成\n",
    "horseResultDf = pd.DataFrame()\n",
    "\n",
    "#保存したhtmlを1つずつ処理\n",
    "for idx, dat in tqdm(htmlDf.iterrows(), total=len(htmlDf)):\n",
    "    horseId = dat['horseId']\n",
    "    htmlBytes = dat['htmlBytes']\n",
    "\n",
    "    if horseId in escapeList:\n",
    "        continue\n",
    "\n",
    "    #BeautifulSoupでHTMLを解析\n",
    "    soup = BeautifulSoup(htmlBytes.decode('euc-jp', 'ignore'), 'html.parser')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    #ヘッダー用のList生成してデータフレームを生成\n",
    "    columns = ['horseId']\n",
    "    #thタグをひとつずつ取り出してListに追加\n",
    "    for head in table.find_all('th'):\n",
    "        columns.append(head.text)\n",
    "    columns += ['raceId', 'jockeyId']\n",
    "    #空のデータフレームを生成\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    #cellごとに分解してlistに追加\n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        #最初の行はヘッダー列なので処理をスキップ\n",
    "        if i == 0:\n",
    "            continue\n",
    "        #競走馬IDを埋め込み\n",
    "        items = [horseId]\n",
    "        cells = row.find_all('td')\n",
    "        #cellごとに分解してlistに追加\n",
    "        for cell in cells:\n",
    "            items.append(cell.text.replace('\\n', ''))\n",
    "        #readIdとjockeyを抽出してlistに追加\n",
    "        items.append(str(cells[4]).split('/race/')[1].split('/')[0])\n",
    "        try:\n",
    "            items.append(str(cells[12]).split('/racent/')[1].split('/')[0])\n",
    "        except:\n",
    "            #たまに騎手にアンカーがいない人がいるから例外処理を追加\n",
    "            items.append('xxxxx')\n",
    "        #データフレームに追加\n",
    "        df.loc[i] = items\n",
    "    #データフレームに結合\n",
    "    horseResultDf = pd.concat([horseResultDf, df], axis=0)\n",
    "#なんか重複するときがあるからhorseIdと日付をキーに重複行削除\n",
    "horseResultDf = horseResultDf[~horseResultDf[['horseId', '日付']].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 1366.60it/s]\n"
     ]
    }
   ],
   "source": [
    "df = horseResultDf.copy()\n",
    "#着外や除外などのデータを欠損データに変換\n",
    "df['着順'] = pd.to_numeric(df['着順'],errors='coerce')\n",
    "df.dropna(subset=['着順'], inplace=True)\n",
    "#馬体重と体重増減を分割して計測不のデータは欠損データに変換\n",
    "df['馬体重'] = df['馬体重'].map(lambda x: '---(-)' if '不' in x else x)\n",
    "df['体重増減'] = df['馬体重'].str.split('(', expand=True)[1].str[:-1]\n",
    "df['馬体重'] = df['馬体重'].str.split('(', expand=True)[0]\n",
    "df['馬体重'] = pd.to_numeric(df['馬体重'], errors='coerce')\n",
    "df.dropna(subset=['馬体重'], inplace=True)\n",
    "#,を除去後、空の行は0で埋める\n",
    "df['賞金'] = df['賞金'].str.replace(',','')\n",
    "df['賞金'] = pd.to_numeric(df['賞金'], errors='coerce')\n",
    "df['賞金'] = df['賞金'].fillna(0)\n",
    "#レース結果と書式を合わせるために、オッズは単勝に列名を変える\n",
    "df['単勝'] = df['オッズ']\n",
    "#変換不可能なデータを欠損データに変換\n",
    "df['上り'] = pd.to_numeric(df['上り'], errors='coerce')\n",
    "df.dropna(subset={'上り'}, inplace=True)\n",
    "\n",
    "#文字列から数値に変換\n",
    "for clna in ['R', '頭数', '着順', '馬体重', '体重増減', '枠番' ,'馬番']:\n",
    "    df[clna] = df[clna].astype(int)\n",
    "for clna in ['単勝', '人気', '賞金', '斤量', '上り', '着差']:\n",
    "    df[clna] = df[clna].astype(float)\n",
    "\n",
    "#タイムは扱いやすく為に秒に変換しておく\n",
    "df['タイム'] = df['タイム'].map(lambda x: '10:0' if x == '' else x)\n",
    "df['タイム'] = df['タイム'].map(lambda \\\n",
    "                          x:float(x.split(':')[0]) * 60 + float(x.split(':')[1]))\n",
    "df['タイム'] = df['タイム'].map(lambda x: np.nan if x > 550 else x)\n",
    "\n",
    "#horseIdと日付でソート\n",
    "df = df.sort_values(['horseId','日付'], ascending=[True, False]).reset_index(drop=True)\n",
    "for horseId in tqdm(df['horseId'].unique()):\n",
    "    x = df[df['horseId']==horseId]['日付'].to_list()\n",
    "    ilist = []\n",
    "    for i in range(len(x) - 1):\n",
    "        interval = datetime.datetime.strptime(x[i], '%Y/%m/%d') - \\\n",
    "                    datetime.datetime.strptime(x[i+1], '%Y/%m/%d')\n",
    "        ilist.append(interval.days)\n",
    "    ilist += [0]\n",
    "    df.loc[df['horseId']==horseId, '出走間隔'] = ilist\n",
    "df['出走間隔'] = df['出走間隔'].astype(int)\n",
    "\n",
    "#必要な列だけ拾って、列を並べ替え\n",
    "columns = ['horseId', '日付', 'R', 'レース名', 'raceId', '頭数',\n",
    "           '枠番', '馬番', '単勝', '人気', '着順', '騎手', 'jockeyId',\n",
    "           '斤量', 'タイム', '着差', '通過', 'ペース', '上り', '馬体重',\n",
    "           '体重増減', '出走間隔', '賞金']\n",
    "df.to_pickle('./data/horse_result.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
