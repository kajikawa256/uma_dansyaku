{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn import preprocessing\n",
    "import classes.convert_df as con\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYSQLデータを取得します\n",
      "SELECT * FROM RESULT_HORSE;\n",
      "SELECT * FROM RACE;\n",
      "最新のレース結果に戦績データを付与します\n",
      "SELECT * FROM RACE;\n",
      "SELECT * FROM RESULT_HORSE;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa90b4aee2040c484fd18830b52f273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "C:\\Users\\2220216\\AppData\\Local\\Temp\\ipykernel_2580\\1090547431.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データセット作成処理が終了しました\n"
     ]
    }
   ],
   "source": [
    "#データセット作成\n",
    "# def dataset(self):\n",
    "print('MYSQLデータを取得します')\n",
    "\n",
    "gift = con.Main()\n",
    "# DBからデータ取得\n",
    "df = gift.convert_df('RESULT_HORSE','')\n",
    "infoDf = gift.convert_df('RACE','')\n",
    "# レース結果と競走馬戦績にレース情報を結合\n",
    "result = pd.merge(left=df, right=infoDf,\n",
    "            how='left', on='RACE_ID', suffixes=['', '_i'])\n",
    "\n",
    "# 保存したデータを読み込みレース結果とレース情報を結合\n",
    "dataDf = result\n",
    "loadDf = pd.DataFrame()\n",
    "\n",
    "# 加工対象があったら加工実行\n",
    "if len(dataDf) > 0:\n",
    "    print('最新のレース結果に戦績データを付与します')\n",
    "    # 上記のデータに戦績データを付与\n",
    "\n",
    "    tqdm_notebook.pandas()\n",
    "    gift = con.Main()\n",
    "    # DBからデータ取得\n",
    "    dfRaceInfo = gift.convert_df('RACE','')\n",
    "    dfHorseResult = gift.convert_df('RESULT_HORSE','')\n",
    "    # 競走馬戦績にレース情報を結合\n",
    "    dfHorseResulti = pd.merge(left=dfHorseResult, right=dfRaceInfo,\n",
    "                            how='left', on='RACE_ID', suffixes=['', '_i'])\n",
    "    # 戦績テーブルからゴミを除去\n",
    "    df = dfHorseResulti.copy()\n",
    "    columns = []\n",
    "    for cn in df.columns:\n",
    "        if '_i' not in cn:\n",
    "            columns.append(cn)\n",
    "    dfHorseResulti = df[columns]\n",
    "    # 引数のデータフレームをコピー\n",
    "    df = dataDf.copy()\n",
    "    # 戦績データとする列を_1～_9のサフィックスを付与して一度numpy配列にする\n",
    "    cols = np.array([dfHorseResulti.add_suffix(f'_{i}').columns for i in range(1, 10)])\n",
    "    # 列名を1次元配列にreshape\n",
    "    cols = cols.reshape(-1)\n",
    "\n",
    "    # 戦績データ生成関数の定義\n",
    "    def generateHistoricalData(row):\n",
    "        # 日付とhorseIdの抽出\n",
    "        dt = row['RACEDATE']\n",
    "        horseId = row['HORSE_ID']\n",
    "        # 戦績データを日付とhorseIdで絞り込み\n",
    "        na = (\n",
    "            dfHorseResulti[(dfHorseResulti['RACEDATE']<dt)&\n",
    "                            (dfHorseResulti['HORSE_ID']==horseId)]\n",
    "                .head(9)        # 直近9レース分に限定\n",
    "                .to_numpy()     # numpy配列に変換\n",
    "                .reshape(-1)    # 1次元配列に変換\n",
    "        )\n",
    "        # 戦績データのサイズが9レース分無かったら足りないサイズ分nanで埋める\n",
    "        if na.size < cols.size:\n",
    "            naNan = np.array([np.nan for i in range(cols.size - na.size)])\n",
    "            na = np.concatenate([na, naNan])\n",
    "        return na\n",
    "    \n",
    "\n",
    "    # 戦績データを生成してapplyで関数実行\n",
    "    df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
    "\n",
    "    dataAddHis = df\n",
    "    if len(loadDf) >= 0:\n",
    "        dataAddHis = pd.concat([loadDf, dataAddHis], axis=0)\n",
    "else:\n",
    "    dataAddHis = loadDf\n",
    "\n",
    "dataset = dataAddHis\n",
    "\n",
    "print('データセット作成処理が終了しました')\n",
    "    # return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['2023年07月22日', '2023年07月22日', '2023年07月22日', '2023年07月22日',\\n       '2023年07月22日', '2023年07月22日', '2023年07月22日', '2023年07月22日',\\n       '2023年07月22日', '2023年07月22日',\\n       ...\\n       '2024年01月14日', '2024年01月14日', '2024年01月14日', '2024年01月14日',\\n       '2024年01月14日', '2024年01月14日', '2024年01月14日', '2024年01月14日',\\n       '2024年01月14日', '2024年01月14日'],\\n      dtype='object', length=27723)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m datasetP \u001b[38;5;241m=\u001b[39m datasetP[datasetP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANKING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m失格\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m datasetP \u001b[38;5;241m=\u001b[39m datasetP[datasetP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANKING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m未定\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 33\u001b[0m datasetP \u001b[38;5;241m=\u001b[39m \u001b[43mdatasetP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatasetP\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRACEDATE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m年\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m月\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m日\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# return datasetP\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:6175\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6174\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['2023年07月22日', '2023年07月22日', '2023年07月22日', '2023年07月22日',\\n       '2023年07月22日', '2023年07月22日', '2023年07月22日', '2023年07月22日',\\n       '2023年07月22日', '2023年07月22日',\\n       ...\\n       '2024年01月14日', '2024年01月14日', '2024年01月14日', '2024年01月14日',\\n       '2024年01月14日', '2024年01月14日', '2024年01月14日', '2024年01月14日',\\n       '2024年01月14日', '2024年01月14日'],\\n      dtype='object', length=27723)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#データセット前処理\n",
    "# def dataset_Preprocessing(self,dataset):\n",
    "    #データセットのロード\n",
    "data = dataset.copy()\n",
    "#使用する列名を指定\n",
    "resultCol = [\n",
    "    'RACEDATE', 'RACE_ID', 'HORSEFRAME', 'HORSENUMBER', 'HORSE_ID', 'GENDER', 'AGE',\n",
    "        'WEIGHT', 'JOCKEY_ID', 'ODDS', 'POPULAR', 'TORAINER_ID', 'BASE',\n",
    "        'HORSE_WEIGHT', 'WEIGHT_GAIN_LOSS', 'HANDICAP', 'RANKING','RACENUMBER',\n",
    "        'GROUND', 'SPIN', 'DISTANCE', 'WEATHER', 'SITUATION', 'PLACE',\n",
    "        'GRADE', 'LIMIT','HORSE_TOTAL','TIME'\n",
    "]\n",
    "recordCol = [\n",
    "    'RACENUMBER', 'HORSE_TOTAL', 'HORSEFRAME', 'HORSENUMBER', 'ODDS', 'POPULAR', 'RANKING',\n",
    "    'JOCKEY_ID', 'WEIGHT', 'TIME', 'HORSE_WEIGHT',\n",
    "    'WEIGHT_GAIN_LOSS', 'GROUND', 'SPIN', 'DISTANCE',\n",
    "    'WEATHER', 'SITUATION', 'PLACE', 'GRADE', 'LIMIT', 'HANDICAP',\n",
    "]\n",
    "#前N走分戦績の列名を生成\n",
    "recordCol9 = []\n",
    "for i in range(1, 10):\n",
    "    tmpList = list(map(lambda x: x + '_' + str(i), recordCol))\n",
    "    recordCol9 += tmpList\n",
    "#列名を合体\n",
    "COLUMNS = resultCol + recordCol9\n",
    "#データセット\n",
    "datasetP = dataset[COLUMNS]\n",
    "datasetP = datasetP[datasetP['RANKING'] != '中止']\n",
    "datasetP = datasetP[datasetP['RANKING'] != '除外']\n",
    "datasetP = datasetP[datasetP['RANKING'] != '取消']\n",
    "datasetP = datasetP[datasetP['RANKING'] != '失格']\n",
    "datasetP = datasetP[datasetP['RANKING'] != '未定']\n",
    "datasetP = datasetP[datasetP['RACEDATE'].replace('年','/').replace('月','/').replace('日','')]\n",
    "    # return datasetP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンコード\n",
    "class Encode:\n",
    "    # エンコード実行メソッド\n",
    "    def encoding(self, src, fit=False):\n",
    "        df = src.copy()\n",
    "        self.encodeEnvs = self.generateEncodeEnvs()\n",
    "        for key, env in tqdm(self.encodeEnvs.items()):\n",
    "            cols = env['cols']\n",
    "            le = env['encoder']\n",
    "            if fit:\n",
    "                # fitの指示があったらデータフレームから対象の値を取り出して実行\n",
    "                na = df[cols].to_numpy()\n",
    "                tg = na.reshape(-1).tolist()\n",
    "                le.fit(tg)\n",
    "            for col in cols:\n",
    "                # 欠損データ以外の列を取り出す\n",
    "                notNull = df[col][df[col].notnull()]\n",
    "                # エンコード実行してindexをキーにデータフレームに書き込む\n",
    "                df[col] = pd.Series(le.transform(notNull), index=notNull.index)\n",
    "                # エンコードした列はcategory列に変換\n",
    "                df[col] = df[col].astype('category')\n",
    "        cols = COLUMNS\n",
    "        for col in cols:\n",
    "            df[col] = df[col].astype(float)\n",
    "\n",
    "        return df\n",
    "    def generateEncodeEnvs(self):\n",
    "        encodeEnvs = {}\n",
    "        # horseIdだけは勝手が違うので個別に環境を生成\n",
    "        dd = {}\n",
    "        dd['cols'] = ['HORSE_ID']\n",
    "        dd['encoder'] = preprocessing.LabelEncoder()\n",
    "        encodeEnvs['HORSE_ID'] = dd\n",
    "        # それ以外の対象はリスト化してfor文で処理 #カテゴリ変数をラベルエンコード\n",
    "        cols = ['GENDER', 'TORAINER_ID', 'BASE', 'JOCKEY_ID', 'HANDICAP', 'GROUND',\n",
    "                'SPIN', 'WEATHER', 'SITUATION', 'PLACE', 'GRADE', 'LIMIT']\n",
    "        for col in cols:\n",
    "            dd = {}\n",
    "            dd['cols'] = [s for s in resultCol if col in s]\n",
    "            dd['encoder'] = preprocessing.LabelEncoder()\n",
    "            encodeEnvs[col] = dd\n",
    "        return encodeEnvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #エンコード\n",
    "# #ラベルエンコーディング関数の定義\n",
    "# def labelEncode(df, target, recflg=False):\n",
    "#     #複数列のラベルエンコーディング関数の定義\n",
    "#     def listEncoder(tdf, le, cols):\n",
    "#         #データフレームのコピー\n",
    "#         tdf_ = tdf.copy()\n",
    "#         #列名から値を取り出す\n",
    "#         encoList = []\n",
    "#         for col in cols:\n",
    "#             encoList += tdf_[col].unique().tolist()\n",
    "#         #エンコーダーを生成\n",
    "#         le.fit(encoList)\n",
    "#         #複数列分ループ\n",
    "#         for col in tqdm(cols, desc=cols[0]):\n",
    "#             #欠損データ以外の列を取り出す\n",
    "#             notNull = tdf_[col][tdf_[col].notnull()]\n",
    "#             #エンコード実行してindexをキーにデータフレームに書き込む\n",
    "#             tdf_[col] = pd.Series(le.transform(notNull), index=notNull.index)\n",
    "#             #エンコードした列はcategory列に変換\n",
    "#             tdf_[col] = tdf_[col].astype('category')\n",
    "#         return tdf_, le\n",
    "#     #データフレームのコピー\n",
    "#     tdf = df.copy()\n",
    "#     #ラベルエンコーダーをインスタンス\n",
    "#     le = preprocessing.LabelEncoder()\n",
    "#     #戦績かどうかで分岐\n",
    "#     if not recflg:\n",
    "#         #リストかどうかで分岐\n",
    "#         if type(target) == list:\n",
    "#             #エンコーダーの生成\n",
    "#             le.fit(tdf[target])\n",
    "#             #欠損データ以外の列を取り出す\n",
    "#             notNull = tdf[target][tdf[target].notnull()]\n",
    "#             #エンコード実行してindexをキーにデータフレームに書き込む\n",
    "#             tdf[target] = pd.Series(le.transform(notNull), index=notNull.index)\n",
    "#             #エンコードした列はcategory列に変換\n",
    "#             tdf[target] = tdf[target].astype('category')\n",
    "#         else:\n",
    "#             #戦績以外で複数データだったら複数列エンコードの実行\n",
    "#             tdf, le = listEncoder(tdf, le, target)\n",
    "#     else:\n",
    "#         #戦績データは列名にサフィックスを付与したリストを生成\n",
    "#         cols9 = [target] + [target + '_' + str(i) for i in range(1, 10)]\n",
    "#         #複数列エンコードの実行\n",
    "#         tdf, le = listEncoder(tdf, le, cols9)\n",
    "#     #データフレームとエンコーダーをreturn\n",
    "#     return tdf, le\n",
    "\n",
    "# #データフレームコピー\n",
    "# df = datasetP.copy()\n",
    "# #カテゴリ変数をラベルエンコード\n",
    "# horseList = ['HORSE_ID']\n",
    "# df, leHorse = labelEncode(df,horseList)\n",
    "# df, leGender = labelEncode(df,'GENDER')\n",
    "# df, leTrainer = labelEncode(df,'TRAINER_ID')\n",
    "# df, leHomeBase = labelEncode(df,'BASE')\n",
    "# df, lejockey = labelEncode(df,'JOCKEY_ID',recflg=True)\n",
    "# df, leHandi = labelEncode(df,'HANDECAP',recflg=True)\n",
    "# df, leType = labelEncode(df,'GROUND',recflg=True)\n",
    "# df, leDir = labelEncode(df,'SPIN',recflg=True)\n",
    "# df, leWether = labelEncode(df,'WEATHER',recflg=True)\n",
    "# df, leCondition = labelEncode(df,'SITUATION',recflg=True)\n",
    "# df, lePlace = labelEncode(df,'PLACE',recflg=True)\n",
    "# df, leGrade = labelEncode(df,'GRADE', recflg=True)\n",
    "# df, leRegulation = labelEncode(df,'LIMIT',recflg=True)\n",
    "# #量的変数の列名を生成\n",
    "# numericCols = ['AGE']\n",
    "# cols1 = ['HORSE_FRAME','HORSE_NUMBER','ODDS','POPULAR','WEIGHT','HORSE_WEIGHT',\n",
    "#          'WEIGHT_GAIN_LOSS','RANKING','RACENUMBER','DISTANCE']\n",
    "# cols2 = ['HORSE_TOTAL','RANKING','TIME']\n",
    "# numericCols += cols1\n",
    "# cols3 =cols1 + cols2\n",
    "# for i in range(1,10):\n",
    "#     numericCols += map(lambda x: x + '_' + str(i),cols3)\n",
    "# #量的変数に対して片変数を実行\n",
    "# for col in tqdm(numericCols):\n",
    "#     df[col] = df[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['HORSE_ID'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#学習\u001b[39;00m\n\u001b[0;32m      2\u001b[0m enc \u001b[38;5;241m=\u001b[39m Encode()\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasetP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#着順から正解列を生成\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANKING\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[57], line 12\u001b[0m, in \u001b[0;36mEncode.encoding\u001b[1;34m(self, src, fit)\u001b[0m\n\u001b[0;32m      9\u001b[0m le \u001b[38;5;241m=\u001b[39m env[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# fitの指示があったらデータフレームから対象の値を取り出して実行\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     na \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m     13\u001b[0m     tg \u001b[38;5;241m=\u001b[39m na\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     14\u001b[0m     le\u001b[38;5;241m.\u001b[39mfit(tg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:1072\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:1113\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:6175\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6174\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['HORSE_ID'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "#学習\n",
    "enc = Encode()\n",
    "df = enc.encoding(src=datasetP, fit=True)\n",
    "#着順から正解列を生成\n",
    "df['Act'] = df['RANKING'].map(lambda x: 1 if x <= 3 else 0)\n",
    "#日付をキーに訓練データと検証データに分割\n",
    "sepdt = '2023年01月01日'\n",
    "train = df[df['RACEDATE']<sepdt]\n",
    "test = df[df['RACEDATE']>=sepdt]\n",
    "\n",
    "#それぞれ教師データと訓練データに分割\n",
    "train_x = train.drop(['RACEDATE','RANKING','RACE_ID','Act','ODDS','POPULAR'],axis=1)\n",
    "train_y = train['Act']\n",
    "test_x = train.drop(['RACEDATE','RANKING','raceId','Act','ODDS','POPULAR'],axis=1)\n",
    "test_y = train['Act']\n",
    "\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#学習モデルの保存\n",
    "import pickle\n",
    "with open('model.pickle', mode='wb') as f:\n",
    "    pickle.dump(モデル名,f,protocol=2)\n",
    "\n",
    "# モデルのオープン\n",
    "with open('model.pickle', mode='rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
