{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classes.convert_df as con\n",
    "import create_dataset as cr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "的中:HIT,　レース:RACE,　結果情報:RESULT_HORSE,  \n",
    "予想情報:PREDICTION_HORSE,　払い戻し詳細:HIT_DETAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046153846153846156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\classes\\wins.py:71: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  win = int(self.wins(jockey_id,racedate)['count(RANKING)'])\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\classes\\wins.py:72: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  race = int(self.all_race(jockey_id,racedate)['count(RANKING)'])\n"
     ]
    }
   ],
   "source": [
    "import classes.wins as win\n",
    "data = win.JOCKEY()\n",
    "a = data.wins(\"01207\",\"2024年01月30日\")\n",
    "b = data.all_race(\"01207\",\"2024年01月30日\")\n",
    "\n",
    "result = data.win_lose(\"01207\",\"2024年01月30日\")\n",
    "print(a)\n",
    "print(b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM RACE;\n",
      "SELECT * FROM RESULT_HORSE;\n",
      "SELECT * FROM RACE;\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_sql() got an unexpected keyword argument 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m race \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mconvert_df(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRACE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m horse \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mconvert_df(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESULT_HORSE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m race \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_df\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRACE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: read_sql() got an unexpected keyword argument 'engine'"
     ]
    }
   ],
   "source": [
    "dataset = con.Main()\n",
    "race = dataset.convert_df('RACE','')\n",
    "horse = dataset.convert_df('RESULT_HORSE','')\n",
    "race = pd.read_sql(dataset.convert_df('RACE',''),engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新します\n",
      "レース結果のデータをロードします\n",
      "SELECT * FROM RESULT_HORSE;\n",
      "SELECT * FROM RACE;\n",
      "レース結果に戦績データを付与します\n",
      "SELECT * FROM RACE;\n",
      "SELECT * FROM RESULT_HORSE;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fe5b82a7a549f286b0209978dc532c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n",
      "c:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols] = df.progress_apply(generateHistoricalData, axis=1, result_type='expand')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データセットをファイルに保存します\n",
      "データセットの更新が完了しました\n"
     ]
    }
   ],
   "source": [
    "da = cr.Dataset(load=False)\n",
    "da.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "レース結果のデータをロードします\n",
      "レース結果に戦績データを付与します\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mMain()\n\u001b[1;32m----> 2\u001b[0m da \u001b[38;5;241m=\u001b[39m \u001b[43mcr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m race \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mconvert_df(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRACE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m horse \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mconvert_df_horse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESULT_HORSE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019102542\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRACE_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:20\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__encodeEnvs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__generateEncodeEnvs()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__updateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:157\u001b[0m, in \u001b[0;36mDataset.__updateDataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mレース結果に戦績データを付与します\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# 上記のデータに戦績データを付与\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m dataAddHis \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddHistrical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataDf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataAddHis)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loadDf) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:223\u001b[0m, in \u001b[0;36mDataset.addHistrical\u001b[1;34m(srcdf)\u001b[0m\n\u001b[0;32m    221\u001b[0m df \u001b[38;5;241m=\u001b[39m dfHorseResulttt\u001b[38;5;241m.\u001b[39mcopy()     \u001b[38;5;66;03m#もともとはsrcdf\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# 戦績データとする列を_1～_9のサフィックスを付与して一度numpy配列にする\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([dfHorseResulti\u001b[38;5;241m.\u001b[39madd_suffix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# 列名を1次元配列にreshape\u001b[39;00m\n\u001b[0;32m    225\u001b[0m cols \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\2220216\\Desktop\\uma_dansyaku\\python\\create_dataset.py:223\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    221\u001b[0m df \u001b[38;5;241m=\u001b[39m dfHorseResulttt\u001b[38;5;241m.\u001b[39mcopy()     \u001b[38;5;66;03m#もともとはsrcdf\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# 戦績データとする列を_1～_9のサフィックスを付与して一度numpy配列にする\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mdfHorseResulti\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)])\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# 列名を1次元配列にreshape\u001b[39;00m\n\u001b[0;32m    225\u001b[0m cols \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:4969\u001b[0m, in \u001b[0;36mNDFrame.add_suffix\u001b[1;34m(self, suffix, axis)\u001b[0m\n\u001b[0;32m   4963\u001b[0m mapper \u001b[38;5;241m=\u001b[39m {axis_name: f}\n\u001b[0;32m   4964\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Optional[Self]\",\u001b[39;00m\n\u001b[0;32m   4965\u001b[0m \u001b[38;5;66;03m# expected \"Self\")\u001b[39;00m\n\u001b[0;32m   4966\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"rename\" of \"NDFrame\" has incompatible type\u001b[39;00m\n\u001b[0;32m   4967\u001b[0m \u001b[38;5;66;03m# \"**Dict[str, partial[str]]\"; expected \"Union[str, int, None]\"\u001b[39;00m\n\u001b[0;32m   4968\u001b[0m \u001b[38;5;66;03m# error: Keywords must be strings\u001b[39;00m\n\u001b[1;32m-> 4969\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rename(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmapper)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:1059\u001b[0m, in \u001b[0;36mNDFrame._rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         index \u001b[38;5;241m=\u001b[39m mapper\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_inplace_and_allows_duplicate_labels(inplace)\n\u001b[1;32m-> 1059\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis_no, replacements \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m((index, columns)):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m replacements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:6685\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6553\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6555\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6556\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6557\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6683\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6685\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6688\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6689\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:576\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 576\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py:645\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    643\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 645\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = con.Main()\n",
    "da = cr.Dataset()\n",
    "race = dataset.convert_df('RACE','')\n",
    "horse = dataset.convert_df_horse('RESULT_HORSE','2019102542').sort_values('RACE_ID',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = cr.Dataset()\n",
    "da = da.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14024\\2901453537.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/dataset.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/dataset.pkl')\n",
    "df = df.dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
